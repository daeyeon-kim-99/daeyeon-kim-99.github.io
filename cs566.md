---
layout: default
title: 2D Lower-Body Joint Prediction
---
<script>
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    }
  };
</script>
<script id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>

<style>
  body {
    background-color: #f8fafc;
    color: #1f2933;
    font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI",
      sans-serif;
  }

  .page-content {
    max-width: 1200px;
    margin: 0 auto;
    padding: 0 1.5rem 3.5rem;
  }

  a {
    color: #2563eb;
  }
  a:hover {
    color: #1d4ed8;
  }

  h1, h2, h3 {
    color: #0f172a;
    letter-spacing: 0.02em;
  }

  .page-header {
    background-image: linear-gradient(135deg, #1e293b, #0f766e);
    box-shadow: 0 12px 30px rgba(15, 23, 42, 0.3);
    border-bottom: none;
    padding-bottom: 4.5rem;
  }

  .page-header .project-name,
  .page-header .site-title {
    color: #e0f2fe;
    font-weight: 800;
    letter-spacing: 0.04em;
  }

  .page-header .project-tagline,
  .page-header .site-description {
    color: #bae6fd;
    font-weight: 500;
  }

  .page-header h1 {
    color: #e0f2fe !important;
    font-weight: 800;
    letter-spacing: 0.04em;
  }

  .page-header h2 {
    color: #bae6fd !important;
    font-weight: 500;
  }

  .header-cta {
    margin-top: -3.2rem;
    margin-bottom: 2.2rem;
    text-align: center;
    position: relative;
    z-index: 2;
  }

  .header-btn {
    display: inline-flex;
    align-items: center;
    gap: 0.45rem;
    padding: 0.55rem 1.6rem;
    border-radius: 999px;
    border: 1px solid rgba(191, 219, 254, 0.95);
    background: rgba(15, 23, 42, 0.26);
    color: #e5e7eb;
    font-size: 0.88rem;
    font-weight: 500;
    text-decoration: none;
    backdrop-filter: blur(10px);
    transition: all 0.16s ease-out;
  }

  .header-btn:hover {
    border-color: #38bdf8;
    background: rgba(15, 23, 42, 0.4);
    color: #f9fafb;
    box-shadow: 0 10px 25px rgba(15, 23, 42, 0.4);
    transform: translateY(-1px);
  }

  .header-btn svg {
    width: 17px;
    height: 17px;
    fill: currentColor;
  }

  blockquote {
    border-left: 4px solid #93c5fd;
    margin: 1.2rem 0;
    padding: 0.5rem 1rem;
    background-color: #eff6ff;
    border-radius: 0 0.75rem 0.75rem 0;
    color: #1e3a8a;
  }

  .footer-note {
    margin-top: 3rem;
    padding-top: 1.2rem;
    border-top: 1px solid #e5e7eb;
    font-size: 0.85rem;
    color: #6b7280;
  }

  .footer-sub {
    display: block;
    margin-top: 0.15rem;
    font-size: 0.8rem;
  }

  .hero-image {
    margin-top: 1.0rem;
    margin-bottom: 2.2rem;
    text-align: center;
  }

  .hero-image img {
    max-width: 100%;
    height: auto;
    border-radius: 1.25rem;
    box-shadow: 0 18px 45px rgba(15, 23, 42, 0.35);
  }

  /* Figure layout: loss / PCK side-by-side */
  .figure-grid {
    display: flex;
    flex-direction: column;
    gap: 1.6rem;
    margin: 1rem 0 2.2rem;
  }

  .figure-row {
    display: flex;
    flex-wrap: wrap;
    gap: 1rem;
    justify-content: center;
  }

  .figure-card {
    flex: 1 1 260px;
    max-width: 420px;
    background-color: #ffffff;
    border-radius: 1rem;
    padding: 0.75rem 0.9rem 1rem;
    box-shadow: 0 12px 28px rgba(15, 23, 42, 0.12);
    border: 1px solid #e5e7eb;
  }

  .figure-card img {
    width: 100%;
    height: auto;
    border-radius: 0.75rem;
    display: block;
  }

  .figure-caption {
    font-size: 0.8rem;
    margin-top: 0.4rem;
    color: #4b5563;
  }

  .exp-title {
    font-size: 0.95rem;
    font-weight: 600;
    color: #111827;
    margin: 0.2rem 0 0.2rem;
  }

  .exp-note {
    font-size: 0.85rem;
    color: #4b5563;
    margin: -0.2rem 0 0.6rem;
  }

  /* For vertically stacked, larger qualitative sample images */
  .vertical-stack {
    display: flex;
    flex-direction: column;
    gap: 1.5rem;
    align-items: center;
    margin-top: 0.8rem;
    margin-bottom: 1.8rem;
  }

  .sample-card {
    flex: none;
    width: 650px;
    max-width: 95%;
    background-color: #ffffff;
    border-radius: 1rem;
    padding: 1rem 1.2rem 1.4rem;
    box-shadow: 0 12px 28px rgba(15, 23, 42, 0.12);
    border: 1px solid #e5e7eb;
  }

  .sample-card img {
    width: 100%;
    max-width: 600px;
    height: auto;
    border-radius: 0.75rem;
    display: block;
    margin: 0 auto;
  }

  .figure-card-large {
    max-width: 720px;   /* 원하면 650~800px 정도로 조절 */
  }
</style>

<div class="header-cta">
  <a class="header-btn"
     href="https://github.com/daeyeon-kim-99/CS566_Project"
     target="_blank" rel="noopener">
    <svg viewBox="0 0 16 16" aria-hidden="true">
      <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 
      7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 
      1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 
      0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 
      2.2.82a7.65 7.65 0 0 1 2-.27c.68 0 1.36.09 2 .27 1.53-1.04 
      2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 
      1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 
      1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.01 
      8.01 0 0 0 16 8c0-4.42-3.58-8-8-8z"/>
    </svg>
    View on GitHub
  </a>
</div>

<div class="hero-image">
  <img src="/assets/images/sample1(60K).png" alt="Squat pose prediction demo (60K subset sample 1)">
</div>

# Overview & Motivation

Many people train or rehabilitate at home without professional guidance, making it difficult to evaluate whether 
their movements like **squats** are performed safely. Subtle misalignments in the hips, knees, or ankles are often 
hard to detect, yet even small mistakes can lead to long-term joint issues. To address this challenge, 
this project focuses on accurately estimating **2D lower-body joints** (hips, knees, ankles) from a single 
RGB image to provide a clearer understanding of posture and movement quality.

---

# Problem Setting

**Input**

- A cropped RGB image of a person, resized to **256 × 192**.

**Output**

- 2D locations of **six lower-body joints**:
  - Left / Right hip  
  - Left / Right knee  
  - Left / Right ankle  

**Formulation**

We treat this as a **heatmap prediction** task:

- For each joint *j*, the model predicts a heatmap of size **64 × 48**.  
- Brighter regions mean higher confidence.  
- The final joint coordinates are obtained by taking the **argmax** position in each heatmap.

---

# Dataset & Preprocessing

<div class="figure-grid">
  <div class="figure-row">
    <div class="figure-card figure-card-large">
      <img src="/assets/images/coco1.png"
           alt="COCO lower-body subsets visualization">
    </div>
  </div>
</div>

We build our training data from the **COCO keypoints** dataset.

### COCO Subsets

- **Full COCO (~250K annotations)**  
  General poses, lots of variety, but many partially visible legs.

- **Mini COCO (20K annotations)**  
  Small subset used for quick baselines and debugging.

- **Lower-Body Fully Visible (60K annotations)**  
  Filtered subset where **all six lower-body joints** are visible and annotated.  
  → Cleaner supervision, more relevant to leg-focused tasks.

### Preprocessing Pipeline  

1. Load COCO annotation and **person bounding box**  
2. Crop to the person and resize to **256 × 192**  
3. Normalize using **ImageNet mean / std**  
4. For each of the 6 joints:
   - Downsample GT coordinate by 4 → heatmap size **64 × 48**
   - Draw a **Gaussian** centered at that location  
   - Store **visibility weight** from COCO **V** flag

Outputs per sample:

- `image` → `(3, 256, 192)`  
- `target` → `(6, 64, 48)` heatmaps  
- `target_weight` → visibility mask for 6 joints

---

# Model Architectures

We compare three **heatmap-based** models.

### 1. ResNet18 Baseline

<div class="figure-grid">
  <div class="figure-row">
    <div class="figure-card figure-card-large">
      <img src="/assets/images/Slide6.png"
           alt="COCO lower-body subsets visualization">
    </div>
  </div>
</div>

A standard top-down pose estimation style model:

- **Input:** `(B, 3, 256, 192)`
- **Backbone:** ResNet18, final feature map from `layer4` → `(B, 512, 8, 6)`
- **Upsampling head:** 3× deconv blocks (stride 2) → `(B, 256, 64, 48)`
- **Prediction head:** `3×3` conv `256 → 6`
- **Output:** 6 heatmaps `(B, 6, 64, 48)`

---

### 2. ResNet18-FPN (Multi-scale Features)

<div class="figure-grid">
  <div class="figure-row">
    <div class="figure-card figure-card-large">
      <img src="/assets/images/Slide12.png"
           alt="COCO lower-body subsets visualization">
    </div>
  </div>
</div>

To better handle scale and context, we add an **FPN-style**:

This helps the model learn more about Local edges (knees, ankles) and 
Global body structure (hip–knee–ankle alignment)

- **Input:** `(B, 3, 256, 192)`
- **Backbone:** ResNet18, using feature maps from `layer2` (1/8), `layer3` (1/16), modified `layer4` (1/16 with dilation)
- **FPN fusion:**  
  - `1×1` conv projections to 256 channels  
  - upsample deeper features and sum (`l2 + l3_up + l4_up`) → fused feature `(B, 256, 32, 24)` (1/8)
- **Upsampling head:** 1× deconv (kernel=4, stride=2) → `(B, 256, 64, 48)`
- **Prediction head:** `3×3` conv `256 → 6`
- **Output:** 6 heatmaps `(B, 6, 64, 48)`

---

### 3. Simple Dilated CNN

<div class="figure-grid">
  <div class="figure-row">
    <div class="figure-card figure-card-large">
      <img src="/assets/images/Slide15.png"
           alt="COCO lower-body subsets visualization">
    </div>
  </div>
</div>

We want to test on even simpler model so we made model with dilated convolution layers.

Dilated convs give a **large receptive field**  
→ the model “sees” the whole hip–knee–ankle chain without heavy downsampling.

- **Input:** `(B, 3, 256, 192)`
- **Conv block 1:** `7×7` conv, stride 2 → `(B, 32, 128, 96)`
- **Conv block 2:** `5×5` conv, stride 2 → `(B, 64, 64, 48)`
- **Dilated stack:** 4× residual blocks (channels = 64) with dilation `1 → 2 → 4 → 1`  
  (spatial size kept at `64 × 48`)
- **Head:** `3×3` conv `64 → 64`, then `1×1` conv `64 → 6`
- **Output:** 6 heatmaps `(B, 6, 64, 48)`


---

# Training & Loss Function

### Heatmap Targets

For each joint $j$:

1. Convert GT coordinate from image space $(256 \times 192)$ → heatmap space $(64 \times 48)$  
2. Draw a **2D Gaussian** centered at $(x_j, y_j)$:

   $$
   H_j(x, y) = \exp\left( -\frac{(x - x_j)^2 + (y - y_j)^2}{2\sigma^2} \right)
   $$

3. Invisible or unannotated joints → zero heatmap + weight 0

### JointsMSELoss 

1. For each sample $i$, joint $j$:

   - Flatten heatmaps  
   - Compute per-joint MSE:

     $$
     \ell_{ij} = \frac{1}{N_p} \sum_p \left( \hat{H}_{ij}(p) - H_{ij}(p) \right)^2
     $$

2. Multiply by **visibility weight** $w_{ij}$:

   - visible → $w_{ij} = 1$  
   - invisible / uncertain → $w_{ij} = 0$

3. Average over 6 joints:

   $$
   L_i = \frac{1}{6} \sum_{j=1}^{6} w_{ij}\,\ell_{ij}
   $$

4. Average over batch:

   $$
   L = \frac{1}{B} \sum_{i=1}^{B} L_i
   $$

### Optimization

- **Optimizer:** Adam  
- **Learning rate:** `0.001`  
- **Weight decay:** `0.0001`  
- **Epochs:**  
  - ResNet18: 30–50 on the 20K, 250K dataset  
  - ResNet18-FPN: 30 on the 60K subset  
  - Simple CNN: up to 80–160 epochs on the 60K subset  

---

# Evaluation Metric: PCK@0.05

We evaluate accuracy using **PCK@0.05** and **PCK@0.10** (Percentage of Correct Keypoints) but we used 0.05 mainly:

- A joint is counted as **correct** if  
  `distance(pred, GT) < 0.05 × image size`

---

# Experiments & Results

> ⚠️ **Important note on loss interpretation**  
> Because the loss function divides by **6 joints regardless of visibility**,  
> images that contain **invisible or occluded lower-body joints** contribute  
> artificially low loss values during validation.  
> 
> In the validation set, many samples include legs that are partially outside the image  
> or fully occluded by objects or other people. These joints receive a visibility weight of 0  
> and thus **do not contribute to the heatmap error**, but the final loss is still divided by 6.
> 
> This effect causes the **validation loss to appear lower than the training loss**

### ResNet18 · Mini COCO (20K) + Full COCO (250K)

<div class="figure-grid">
  <div class="exp-title">20K mini COCO · 30 epochs</div>
  <div class="figure-row">
    <div class="figure-card">
      <img src="/assets/images/loss_curve30(20K).png"
           alt="ResNet18 mini COCO 20K - loss curve up to 30 epochs">
      <div class="figure-caption">
        Training / validation loss (30 epochs).
      </div>
    </div>
    <div class="figure-card">
      <img src="/assets/images/pck_curves30(20K).png"
           alt="ResNet18 mini COCO 20K - PCK curves up to 30 epochs">
      <div class="figure-caption">
        PCK@0.05 over 30 epochs on the mini COCO subset.
      </div>
    </div>
  </div>

  <div class="exp-title">20K mini COCO · 50 epochs</div>
  <div class="figure-row">
    <div class="figure-card">
      <img src="/assets/images/loss_curve_e50(20K).png"
           alt="ResNet18 mini COCO 20K - loss curve up to 50 epochs">
      <div class="figure-caption">
        Training / validation loss (50 epochs).
      </div>
    </div>
    <div class="figure-card">
      <img src="/assets/images/pck_curves_e50(20K).png"
           alt="ResNet18 mini COCO 20K - PCK curves up to 50 epochs">
      <div class="figure-caption">
        PCK@0.05 when training is extended to 50 epochs.
      </div>
    </div>
  </div>

  <div class="exp-title">Full COCO (250K) · 30 epochs</div>
  <div class="figure-row">
    <div class="figure-card">
      <img src="/assets/images/loss_curve_e30(250K).png"
           alt="ResNet18 full COCO 250K - loss curve">
      <div class="figure-caption">
        ResNet18 · full COCO (250K) – loss over 30 epochs.
      </div>
    </div>
    <div class="figure-card">
      <img src="/assets/images/pck_curves_e30(250K).png"
           alt="ResNet18 full COCO 250K - PCK curve">
      <div class="figure-caption">
        ResNet18 · full COCO (250K) – PCK@0.05 over 30 epochs.
      </div>
    </div>
  </div>
</div>

---

### ResNet18-FPN · Lower-Body 60K

<div class="figure-grid">
  <div class="exp-title">Lower-body fully visible 60K · 30 epochs</div>
  <div class="figure-row">
    <div class="figure-card">
      <img src="/assets/images/loss_curve_e30(60K).png"
           alt="ResNet18-FPN lower-body 60K - loss curve">
      <div class="figure-caption">
        ResNet18-FPN · lower-body 60K – loss curve (30 epochs).
      </div>
    </div>
    <div class="figure-card">
      <img src="/assets/images/pck_curve_e30(60K).png"
           alt="ResNet18-FPN lower-body 60K - PCK curve">
      <div class="figure-caption">
        ResNet18-FPN · lower-body 60K – PCK@0.05 over 30 epochs.
      </div>
    </div>
  </div>
</div>

---

### Simple Dilated CNN · Lower-Body 60K (80 vs 160 epochs)

<div class="figure-grid">
  <div class="exp-title">Dilated CNN on 60K · 80 epochs</div>
  <div class="figure-row">
    <div class="figure-card">
      <img src="/assets/images/loss_curve_e80.png"
           alt="Dilated CNN lower-body 60K - loss curve 80 epochs">
      <div class="figure-caption">
        Dilated CNN · 60K – loss curve (80 epochs).
      </div>
    </div>
    <div class="figure-card">
      <img src="/assets/images/pck_curve_e80.png"
           alt="Dilated CNN lower-body 60K - PCK curve 80 epochs">
      <div class="figure-caption">
        Dilated CNN · 60K – PCK@0.05 over 80 epochs.
      </div>
    </div>
  </div>

  <div class="exp-title">Dilated CNN on 60K · 160 epochs</div>
  <div class="figure-row">
    <div class="figure-card">
      <img src="/assets/images/loss_curve_e160.png"
           alt="Dilated CNN lower-body 60K - loss curve 160 epochs">
      <div class="figure-caption">
        Dilated CNN · 60K – loss curve (160 epochs).
      </div>
    </div>
    <div class="figure-card">
      <img src="/assets/images/pck_curve_e160.png"
           alt="Dilated CNN lower-body 60K - PCK curve 160 epochs">
      <div class="figure-caption">
        Dilated CNN · 60K – PCK@0.05 over 160 epochs.
      </div>
    </div>
  </div>
</div>

---

# Qualitative Comparison: Sample 1 & Sample 2

Below we provide qualitative comparisons across all models using **sample1** and **sample2**.  

## 1️⃣ ResNet18 · Mini COCO (20K)

### **Sample 1 (20K)**

<div class="vertical-stack">
  <div class="sample-card">
    <img src="/assets/images/sample1(20K)_e30.png" alt="Sample 1 — 20K · 30 epochs">
    <div class="figure-caption">Sample 1 — 20K · 30 epochs</div>
  </div>

  <div class="sample-card">
    <img src="/assets/images/sample1(20K)_e50.png" alt="Sample 1 — 20K · 50 epochs">
    <div class="figure-caption">Sample 1 — 20K · 50 epochs</div>
  </div>
</div>

---

### **Sample 2 (20K)**

<div class="vertical-stack">
  <div class="sample-card">
    <img src="/assets/images/sample2(20K)_e30.png" alt="Sample 2 — 20K · 30 epochs">
    <div class="figure-caption">Sample 2 — 20K · 30 epochs</div>
  </div>

  <div class="sample-card">
    <img src="/assets/images/sample2(20K)_e50.png" alt="Sample 2 — 20K · 50 epochs">
    <div class="figure-caption">Sample 2 — 20K · 50 epochs</div>
  </div>
</div>

<table style="border-collapse: collapse; margin: 1.5rem auto; min-width: 360px; font-family: SFMono-Regular,ui-monospace,Menlo,Monaco,Consolas,'Liberation Mono','Courier New',monospace; font-size: 0.9rem;">
  <thead>
    <tr>
      <th style="padding: 0.5rem 1.2rem; border-bottom: 2px solid #cbd5e1; text-align:left;"></th>
      <th style="padding: 0.5rem 1.2rem; border-bottom: 2px solid #cbd5e1; text-align:left;"></th>
      <th style="padding: 0.5rem 1.2rem; border-bottom: 2px solid #cbd5e1; text-align:right;">Epoch30</th>
      <th style="padding: 0.5rem 1.2rem; border-bottom: 2px solid #cbd5e1; text-align:right;">Epoch50</th>
    </tr>
  </thead>
  <tbody>
    <tr style="background:#e5ebf0;">
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1;" rowspan="2">Sample1</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1;">Loss</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.003743</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.004039</td>
    </tr>
    <tr style="background:#e5ebf0;">
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1;">Pck</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.3333</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.1667</td>
    </tr>

    <tr style="background:#e5ebf0;">
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1;" rowspan="2">Sample2</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1;">Loss</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.004139</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.003978</td>
    </tr>
    <tr style="background:#e5ebf0;">
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1;">Pck</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.0000</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.1667</td>
    </tr>
  </tbody>
</table>

**Interpretation — Sample 1 & Sample 2 (20K)**  
- For **Sample 1**, joints are relatively close together, but the predicted heatmaps are still **not very sharp**, showing limited confidence and spatial precision.  
- Even though training is extended from 30 to 50 epochs, both the qualitative maps and the metrics show **no dramatic improvement** — in fact, the **loss even increases**, because the dataset is too small for the model to benefit from longer training.
- **Sample 2** is a harder pose with joints farther apart, requiring stronger spatial reasoning. Here, loss decreases a bit and PCK improves from 0.00 → 0.17, but the overall accuracy is still very low and the heatmaps remain weak and unstable.  
- Together, the 20K subset is **too small and not diverse enough**, so we need **more and better data** (250K / 60K subsets) and stronger architectures to achieve reliable squat pose estimation.

---

## 2️⃣ ResNet18 · Full COCO (250K)

### **Sample 1 (250K)**

<div class="vertical-stack">
  <div class="sample-card">
    <img src="/assets/images/sample1(250K).png" alt="Sample 1 — Full COCO 250K">
    <div class="figure-caption">Sample 1 — Full COCO 250K</div>
  </div>
</div>

---

### **Sample 2 (250K)**

<div class="vertical-stack">
  <div class="sample-card">
    <img src="/assets/images/sample2(250K).png" alt="Sample 2 — Full COCO 250K">
    <div class="figure-caption">Sample 2 — Full COCO 250K</div>
  </div>
</div>

<table style="border-collapse: collapse; margin: 1.5rem auto; min-width: 420px; font-family: SFMono-Regular,ui-monospace,Menlo,Monaco,Consolas,'Liberation Mono','Courier New',monospace; font-size: 0.9rem;">
  <thead>
    <tr>
      <th style="padding: 0.5rem 1.2rem; border-bottom: 2px solid #cbd5e1; text-align:left;"></th>
      <th style="padding: 0.5rem 1.2rem; border-bottom: 2px solid #cbd5e1; text-align:left;"></th>
      <th style="padding: 0.5rem 1.2rem; border-bottom: 2px solid #cbd5e1; text-align:right;">Epoch30<br>(20K)</th>
      <th style="padding: 0.5rem 1.2rem; border-bottom: 2px solid #cbd5e1; text-align:right;">Epoch50<br>(20K)</th>
      <th style="padding: 0.5rem 1.2rem; border-bottom: 2px solid #cbd5e1; text-align:right;">Full COCO<br>(250K)</th>
    </tr>
  </thead>
  <tbody>
    <tr style="background:#e5ebf0;">
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1;" rowspan="2">Sample1</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1;">Loss</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.003743</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.004039</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.003444</td>
    </tr>
    <tr style="background:#e5ebf0;">
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1;">Pck</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.3333</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.1667</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.3333</td>
    </tr>

    <tr style="background:#e5ebf0;">
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1;" rowspan="2">Sample2</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1;">Loss</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.004139</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.003978</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.003892</td>
    </tr>
    <tr style="background:#e5ebf0;">
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1;">Pck</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.0000</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.1667</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.1667</td>
    </tr>
  </tbody>
</table>

**Interpretation — Sample 1 & Sample 2 (20K → full COCO)**  
- After seeing that the **20K subset quickly saturated**, we trained the same backbone on the **full COCO (250K)** split.  
- For **Sample 1**, the loss slightly improves when moving from 20K (0.003743 / 0.004039) to full COCO (0.003444), and PCK recovers from 0.1667 back to **0.3333**. This matches the qualitative heatmaps: on full COCO they are **sharper and more stable** than in the 20K runs.  
- For **Sample 2**, increasing data from 20K to 250K clearly helps: loss decreases from 0.004139 → 0.003892 and PCK rises from 0.0000 (30 epochs) to **0.1667** on both the 50-epoch and full-COCO models. The heatmaps become less noisy and the predicted joints move closer to the ground truth.  
- However, the overall PCK values are still low, especially for the harder Sample 2 pose. This is consistent with what we observed in the dataset: **COCO contains many noisy or incomplete lower-body labels** (e.g., only 3 or fewer visible joints).  
- In other words, scaling from **20K → 250K** gives better stability and accuracy, but performance eventually **saturates because of annotation quality**, which motivates our next step: training on the filtered **60K fully visible lower-body subset** and exploring stronger architectures.

---

## 3️⃣ ResNet18-FPN · Lower-Body Fully Visible (60K)

### **Sample 1 (60K)**

<div class="vertical-stack">
  <div class="sample-card">
    <img src="/assets/images/sample1(60K).png" alt="Sample 1 — 60K fully visible joints">
    <div class="figure-caption">Sample 1 — 60K fully visible joints</div>
  </div>
</div>

---

### **Sample 2 (60K)**

<div class="vertical-stack">
  <div class="sample-card">
    <img src="/assets/images/sample2(60K).png" alt="Sample 2 — 60K fully visible joints">
    <div class="figure-caption">Sample 2 — 60K fully visible joints</div>
  </div>
</div>

<table style="border-collapse: collapse; margin: 1.5rem auto; min-width: 460px; font-family: SFMono-Regular,ui-monospace,Menlo,Monaco,Consolas,'Liberation Mono','Courier New',monospace; font-size: 0.9rem;">
  <thead>
    <tr>
      <th style="padding: 0.5rem 1.2rem; border-bottom: 2px solid #cbd5e1; text-align:left;"></th>
      <th style="padding: 0.5rem 1.2rem; border-bottom: 2px solid #cbd5e1; text-align:left;"></th>
      <th style="padding: 0.5rem 1.2rem; border-bottom: 2px solid #cbd5e1; text-align:right;">Epoch30<br>(20K)</th>
      <th style="padding: 0.5rem 1.2rem; border-bottom: 2px solid #cbd5e1; text-align:right;">Epoch50<br>(20K)</th>
      <th style="padding: 0.5rem 1.2rem; border-bottom: 2px solid #cbd5e1; text-align:right;">Full coco<br>data</th>
      <th style="padding: 0.5rem 1.2rem; border-bottom: 2px solid #cbd5e1; text-align:right;">Full 6joint<br>&amp; FPN</th>
    </tr>
  </thead>
  <tbody>
    <tr style="background:#e5ebf0;">
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1;" rowspan="2">Sample1</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1;">Loss</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.003743</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.004039</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.003444</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.003366</td>
    </tr>
    <tr style="background:#e5ebf0;">
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1;">Pck</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.3333</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.1667</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.3333</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.3333</td>
    </tr>

    <tr style="background:#e5ebf0;">
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1;" rowspan="2">Sample2</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1;">Loss</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.004139</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.003978</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.003892</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.003640</td>
    </tr>
    <tr style="background:#e5ebf0;">
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1;">Pck</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.0000</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.1667</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.1667</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.3333</td>
    </tr>
  </tbody>
</table>

**Interpretation — Sample 1 & Sample 2 (20K → full COCO → 60K + FPN)**  
- **Sample 1**  
  With the **60K fully visible subset + FPN**, the loss drops to **0.003366**, but PCK stays at 0.3333.  
  This matches what we see visually: heatmaps look cleaner and more stable, even if the numbers do not improve much.

- **Sample 2**  
  This pose is more difficult, so the model improves less with small datasets.  
  From 20K, PCK is **0.0** at 30 epochs and only 0.1667 at 50 epochs.  
  Training on the full COCO set lowers the loss (0.004139 → 0.003892), but PCK still stays at 0.1667 because COCO often misses lower-body joints.  
  With the **60K fully visible + FPN model**, the loss decreases to **0.003640** and PCK jumps to **0.3333**, meaning the model finally predicts the far joints more correctly.

- **Overall**  
  Larger datasets help (20K → 250K), but **clean lower-body annotations** and a **stronger FPN architecture** matter much more for stable predictions, especially for difficult poses like Sample 2.

---

## 4️⃣ Simple Dilated CNN (80 / 160 epochs)

Since the qualitative results at **80** and **160** epochs are **completely identical** for Sample 1 and 2, we only include the 80-epoch visualization here.


### **Sample 1 (Dilated CNN)**

<div class="vertical-stack">
  <div class="sample-card">
    <img src="/assets/images/sample1(e80).png" alt="Sample 1 — Dilated CNN · 80 epochs">
    <div class="figure-caption">Sample 1 — Dilated CNN · 80 epochs</div>
  </div>
</div>


---

### **Sample 2 (Dilated CNN)**

<div class="vertical-stack">
  <div class="sample-card">
    <img src="/assets/images/sample2(e80).png" alt="Sample 2 — Dilated CNN · 80 epochs">
    <div class="figure-caption">Sample 2 — Dilated CNN · 80 epochs</div>
  </div>
</div>

**Interpretation — Simple Dilated CNN**

**Sample 1**  
- **The simple dilated CNN works okay when the joints are close together.**  
- But the heatmaps are **less sharp** than those from the FPN models, meaning the predictions are **less confident and less precise**.  
- Overall, the model can handle **simple, compact poses**, but has trouble with **detailed accuracy**.

**Sample 2**  
- This more difficult pose clearly shows the model’s **big weaknesses**.  
- When the joints are **spread far apart**, the simple CNN cannot connect them well, so the heatmaps become **very blurry and low-confidence**.

---

# Summary Across All Samples

**Sample 1**  

<table style="border-collapse: collapse; width: 100%; font-family: 'JetBrains Mono', monospace; font-size: 0.95rem; color:#111;">
  <thead>
    <tr>
      <th style="padding: 0.5rem 1.2rem; border-bottom: 2px solid #cbd5e1; text-align:left;"></th>
      <th style="padding: 0.5rem 1.2rem; border-bottom: 2px solid #cbd5e1; text-align:left;"></th>
      <th style="padding: 0.5rem 1.2rem; border-bottom: 2px solid #cbd5e1; text-align:right;">Epoch30<br>(20K)</th>
      <th style="padding: 0.5rem 1.2rem; border-bottom: 2px solid #cbd5e1; text-align:right;">Epoch50<br>(20K)</th>
      <th style="padding: 0.5rem 1.2rem; border-bottom: 2px solid #cbd5e1; text-align:right;">Full coco<br>data(250K)</th>
      <th style="padding: 0.5rem 1.2rem; border-bottom: 2px solid #cbd5e1; text-align:right;">Full vis<br>6joint & FPN(60K)</th>
      <th style="padding: 0.5rem 1.2rem; border-bottom: 2px solid #cbd5e1; text-align:right;">Simple model<br>Epoch80&160(60K)</th>
    </tr>
  </thead>
  <tbody>
    <tr style="background:#e5ebf0;">
      <td rowspan="2" style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1;">Sample1</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1;">Loss</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.003743</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.004039</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.003444</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.003366</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.003374</td>
    </tr>

    <tr style="background:#e5ebf0;">
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1;">Pck</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.3333</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.1667</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.3333</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.3333</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.5000</td>
    </tr>
  </tbody>
</table>

**Sample 2**

<table style="border-collapse: collapse; width: 100%; font-family: 'JetBrains Mono', monospace; font-size: 0.95rem; color:#111;">
  <thead>
    <tr>
      <th style="padding: 0.5rem 1.2rem; border-bottom: 2px solid #cbd5e1; text-align:left;"></th>
      <th style="padding: 0.5rem 1.2rem; border-bottom: 2px solid #cbd5e1; text-align:left;"></th>
      <th style="padding: 0.5rem 1.2rem; border-bottom: 2px solid #cbd5e1; text-align:right;">Epoch30<br>(20K)</th>
      <th style="padding: 0.5rem 1.2rem; border-bottom: 2px solid #cbd5e1; text-align:right;">Epoch50<br>(20K)</th>
      <th style="padding: 0.5rem 1.2rem; border-bottom: 2px solid #cbd5e1; text-align:right;">Full coco<br>data(250K)</th>
      <th style="padding: 0.5rem 1.2rem; border-bottom: 2px solid #cbd5e1; text-align:right;">Full vis<br>6joint & FPN(60K)</th>
      <th style="padding: 0.5rem 1.2rem; border-bottom: 2px solid #cbd5e1; text-align:right;">Simple model<br>Epoch80&160(60K)</th>
    </tr>
  </thead>

  <tbody>
    <tr style="background:#e5ebf0;">
      <td rowspan="2" style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1;">Sample2</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1;">Loss</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.004139</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.003978</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.003892</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.003640</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.003372</td>
    </tr>

    <!-- Sample2 PCK -->
    <tr style="background:#e5ebf0;">
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1;">Pck</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.0000</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.1667</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.1667</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.3333</td>
      <td style="padding: 0.4rem 1.2rem; border-bottom: 1px solid #cbd5e1; text-align:right;">0.1667</td>
    </tr>
  </tbody>
</table>

- **20K dataset:** Too small → unstable predictions  
- **250K COCO:** Large but noisy → inaccurate lower-body learning  
- **60K fully-visible:** Best quality → best predictions  
- **Dilated CNN:** Works only for simple poses → struggles on complex ones  
- **Conclusion:**  
  → Next model should be *larger* and include **self-attention** to capture joint relationships effectively.

---

# Future Work

Planned directions:

1. **Self-attention on ResNet18-FPN**  
   Better capture long-range joint relationships.

2. **Temporal modeling**  
   Use sequences and temporal convolutions / recurrent models  
   → directly reduce noise and enforce smooth motion.

3. **3D squat analysis**  
   Use our 2D lower-body keypoints as input to a 3D model,  
   estimate knee / hip angles, and give actual squat feedback.

### 3D Video Pose Estimation Demo (Pavllo et al.)

<div style="text-align: center; margin-top: 1rem;">
  <video width="720" controls>
    <source src="/assets/videos/demo_video.mp4" type="video/mp4">
    Your browser does not support the video tag.
  </video>
</div>

**Explanation:**  
This 3D prediction is generated using **VideoPose3D**, a temporal convolutional model.  
Our final goal is to feed our **accurate lower-body 2D joints** into a similar pipeline to compute squat angles, knee tracking, and safe–unsafe posture classification.

---
# Presentation
<div style="text-align: center; margin-top: 1rem;">
  <video width="720" controls>
    <source src="/assets/videos/presentation.mp4" type="video/mp4">
    Your browser does not support the video tag.
  </video>
</div>

---

# References

**[1] Common Objects in Context**  
*Tsung-Yi Lin et al., 2014*  
[Paper](https://arxiv.org/abs/1405.0312)

**[2] Deep Residual Learning for Image Recognition (ResNet)**  
*Kaiming He et al., 2015*  
[Paper](https://arxiv.org/abs/1512.03385)

**[3] Feature Pyramid Networks for Object Detection (FPN)**  
*Tsung-Yi Lin et al., 2016*  
[Paper](https://arxiv.org/abs/1612.03144)

**[4] Simple Baselines for Human Pose Estimation and Tracking**  
*Bin Xiao, Haiping Wu, Yichen Wei, 2018 (Facebook AI Research)*  
[Paper](https://arxiv.org/abs/1804.06208)

**[5] Multi-Scale Context Aggregation by Dilated Convolutions**  
*Fischer Yu, Vladlen Koltun, 2016*  
[Paper](https://arxiv.org/abs/1511.07122)

**[6] 3D Human Pose Estimation in Video with Temporal Convolutions**  
*Dario Pavllo et al., Facebook AI Research, 2019*  
[Paper](https://arxiv.org/abs/1811.11742)