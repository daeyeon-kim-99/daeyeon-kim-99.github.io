---
layout: default
title: 2D Joint Detection
---

# 2D Joint Prediction for Squat Analysis

## ðŸ‘¥ Team

- **Daeyeon Kim**
- **Haeseung Pyun**

---

## ðŸ’¡ Motivation

Squats are one of the most common exercises in strength training.  
However, many people work out without a professional trainer, so it is hard to know whether their squat form is **safe** and **correct**.

Our goal is to build a model that:

- detects **lower-body joints** in squat videos, and  
- provides **clear feedback** on posture quality.

---

## ðŸ” Task & Metrics

We focus on **2D joint prediction** for six lower-body joints:

- Left / Right Hip  
- Left / Right Knee  
- Left / Right Ankle  

We use:

- **PCK@0.05**  
  - A prediction is counted as correct if the predicted joint is within **5% of the image size** from the ground truth location.
- **MSE Loss**  
  - We train the model by minimizing the mean squared error between predicted and ground-truth heatmaps.

---

## ðŸ§  Model & Heatmap Representation

We use a **heatmap-based model**.  
For each joint, the model outputs a 2D heatmap:

- brighter area â†’ higher confidence that the joint is at that location  

You can see an example heatmap here:

> _[TODO: add image]_  
> `![Heatmap example](assets/heatmap_example.png)`

---

## ðŸ§ª Experiments

### 1. Baseline: ResNet18

- We first used a standard **ResNet18** backbone.
- Trained on a **small subset** of COCO (~20K images).

> Result:  
> - The model worked, but we felt it could do better.  
> - When we increased the number of epochs on this small dataset,  
>   the **loss sometimes increased** (overfitting / noisy data).

---

### 2. Larger Dataset: Full COCO

To improve generalization, we trained ResNet18 on the **full COCO keypoint dataset**.

> Result:
> - For both sample cases,  
>   - **loss decreased**,  
>   - **PCK either increased or stayed the same**.
> - But we found a new problem:
>   - Many images have **missing or incomplete annotations**  
>     (e.g., only 3 joints labeled, or even fewer).

Noisy labels made it harder for the model to learn clean lower-body structure.

---

### 3. Filtered Dataset + ResNet18-FPN

To reduce label noise and focus on our task, we created a **filtered dataset**:

- Only images where **all 6 lower-body joints** are visible and have ground-truth labels.

We also slightly modified the model:

- **ResNet18-FPN (Feature Pyramid Network style)**
  - Combines **low-level features** (fine details)  
    and **high-level features** (global context).
  - This is helpful for understanding the relationships between multiple joints.

> Result:
> - Trained on the filtered subset,  
> - **loss further decreased**, and qualitative results were more stable.

---

### 4. Simple Dilated CNN (Our Own Model)

Since our long-term goal is a **simple, lightweight, and easy-to-use model**,  
we also tested a smaller custom model with **dilated convolutions**.

- **Dilated convolution** lets the model see a **larger spatial area**  
  without increasing kernel size or number of parameters.
- This should help the model understand **spatial relationships** between joints.

Training setup:

- Trained on the filtered dataset
- Tried **80 epochs** and **160 epochs**

> Result:
> - For some samples where joints are **close together** (Sample 1),  
>   our simple model performed **almost as well** as larger models.
> - But for samples where joints are **far apart** (Sample 2),  
>   predictions became worse:
>   - Heatmaps had **weak confidence**  
>   - Joint locations were less accurate  
> - Increasing epochs from 80 â†’ 160 did **not** significantly improve results.

This shows the **limitations** of the simple model:  
it is not strong enough to capture long-range relationships between joints.

---

## ðŸ“Š Qualitative Examples

> _[TODO: insert your comparison figures here]_  

- Sample 1 (joints close together)  
  - `![Sample 1 comparison](assets/sample1_compare.png)`
- Sample 2 (joints far apart)  
  - `![Sample 2 comparison](assets/sample2_compare.png)`

You can briefly explain under each image how each model behaves.

---

## âœ… Summary

- **ResNet18 (small dataset)**  
  - Works, but sensitive to small dataset size and noise.
- **ResNet18 (full COCO)**  
  - Better PCK and lower loss, but affected by **noisy / incomplete labels**.
- **Filtered dataset + ResNet18-FPN**  
  - More stable training and better qualitative results.
- **Simple dilated CNN**  
  - Works reasonably well when joints are close,  
  - but struggles when joints are far apart â†’ **underpowered capacity**.

---

## ðŸš€ Future Work

From these experiments, we learned that:

- A very simple model is **not sufficient** for robust squat analysis.
- Modeling **relationships between distant joints** (e.g., hip â†” ankle) is crucial.

**Next steps:**

- Increase model capacity (deeper / wider network).
- Add a **self-attention mechanism** to better capture  
  dependencies between all joints.
- Eventually, extend this system to:
  - 3D pose reconstruction, and  
  - automatic squat quality scoring / feedback.

---

_Last updated: {{ site.time | date: "%Y-%m-%d" }}_
